{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "os.environ[\"TORCH_ROCM_AOTRITON_ENABLE_EXPERIMENTAL\"] = \"1\""
   ],
   "id": "e9cd75025847feac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, Trainer, TrainingArguments, DataCollatorForTokenClassification\n",
    "from datasets import load_dataset\n",
    "import evaluate"
   ],
   "id": "93ab3488da8b62",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "ner_datasets = load_dataset(\"lansinuote/peoples-daily-ner\")",
   "id": "42d765cf41a45bcd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "ner_datasets",
   "id": "975b44fd50e1d0e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "label_list = ner_datasets[\"train\"].features[\"ner_tags\"].feature.names",
   "id": "fbcb99284863c7da",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"hfl/chinese-macbert-base\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"hfl/chinese-macbert-base\", num_labels=len(label_list))"
   ],
   "id": "ab22d83af8871493",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(ner_datasets[\"train\"][0][\"tokens\"])\n",
    "print(ner_datasets[\"train\"][0][\"ner_tags\"])\n",
    "print(len(ner_datasets[\"train\"][0][\"tokens\"]))\n",
    "print(len(ner_datasets[\"train\"][0][\"ner_tags\"]))"
   ],
   "id": "db9260cc7073d96f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "input = tokenizer(ner_datasets[\"train\"][0][\"tokens\"], is_split_into_words=True)\n",
    "input"
   ],
   "id": "8115c0a46bdafd5f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "input.word_ids(0)",
   "id": "38a4f41e5dbfc1a0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "res = tokenizer(\"interesting word\")\n",
    "res"
   ],
   "id": "4a12a18aa51ef5f1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "res.word_ids()",
   "id": "60c22d3c271348ee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def process_function(examples, tokenizer=tokenizer):\n",
    "    labels = []\n",
    "    inputs = tokenizer(examples[\"tokens\"], max_length=128, truncation=True, is_split_into_words=True)\n",
    "    for i, label in enumerate(examples[\"ner_tags\"]):\n",
    "        word_ids = inputs.word_ids(batch_index=i)\n",
    "        label_ids = []\n",
    "        for word_id in word_ids:\n",
    "            if word_id is None:\n",
    "                label_ids.append(-100)\n",
    "            else:\n",
    "                label_ids.append(label[word_id])\n",
    "        labels.append(label_ids)\n",
    "    inputs[\"labels\"] = labels\n",
    "    return inputs\n",
    "\n",
    "# æ–°çš„æµ‹è¯•å‡½æ•°ï¼šåªåœ¨å­è¯å¤„ç†ä¸Šæœ‰å·®å¼‚\n",
    "def process_function_test(examples, tokenizer=tokenizer):\n",
    "    labels = []\n",
    "    inputs = tokenizer(examples[\"tokens\"], max_length=128, truncation=True, is_split_into_words=True)\n",
    "    for i, label in enumerate(examples[\"ner_tags\"]):\n",
    "        word_ids = inputs.word_ids(batch_index=i)\n",
    "        label_ids = []\n",
    "        previous_word_idx = None  # æ·»åŠ è¿™ä¸ªå˜é‡\n",
    "        for word_id in word_ids:\n",
    "            if word_id is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_id != previous_word_idx:  # åªæœ‰è¿™é‡Œä¸åŒ\n",
    "                label_ids.append(label[word_id])\n",
    "            else:\n",
    "                label_ids.append(-100)  # å­è¯æ ‡ç­¾è®¾ä¸º-100\n",
    "            previous_word_idx = word_id  # æ›´æ–°previous_word_idx\n",
    "        labels.append(label_ids)\n",
    "    inputs[\"labels\"] = labels\n",
    "    return inputs\n",
    "\n",
    "\n",
    "ner_datasets[\"train\"].select(range(2)).map(process_function, batched=True, remove_columns=ner_datasets[\"train\"].column_names)"
   ],
   "id": "a010a67a7fa98b5a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "seqeval = evaluate.load(\"seqeval\")",
   "id": "97ee04dbf99bac8d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def eval_matric(pred):\n",
    "    predictions, labels = pred\n",
    "    predictions = predictions.argmax(axis=-1)\n",
    "\n",
    "    real_predictions = [\n",
    "        [label_list[p] for p, l in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    real_labels = [\n",
    "        [label_list[l] for p, l in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = seqeval.compute(predictions=real_predictions, references=real_labels, mode=\"struct\", scheme=\"IOB2\")\n",
    "\n",
    "    flattened_results = {}\n",
    "    for key, value in results.items():\n",
    "        if isinstance(value, dict):\n",
    "            for sub_key, sub_value in value.items():\n",
    "                flattened_results[f\"{key}_{sub_key}\"] = sub_value\n",
    "        else:\n",
    "            flattened_results[key] = value\n",
    "\n",
    "    return flattened_results"
   ],
   "id": "7bf26a0ea809c12b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_args = TrainingArguments(\n",
    "    output_dir=\"./checkpoints-for-nre\",\n",
    "    per_device_train_batch_size=64,\n",
    "    per_device_eval_batch_size=128,\n",
    "    logging_steps=10,\n",
    "    learning_rate=2e-5,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    num_train_epochs=3,\n",
    "    save_strategy=\"epoch\",\n",
    "    report_to=[\"tensorboard\"],\n",
    "    load_best_model_at_end=True,\n",
    "    # logging_first_step=True,\n",
    "    # log_level=\"info\",\n",
    "    # warmup_ratio=0.1,  # æ·»åŠ warmup\n",
    "    # weight_decay=0.01  # æ·»åŠ æƒé‡è¡°å‡\n",
    ")\n",
    "train_args"
   ],
   "id": "110166ff35ef79f3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=train_args,\n",
    "    train_dataset=ner_datasets[\"train\"].map(process_function_test, batched=True, remove_columns=ner_datasets[\"train\"].column_names),\n",
    "    eval_dataset=ner_datasets[\"validation\"].map(process_function_test, batched=True, remove_columns=ner_datasets[\"validation\"].column_names),\n",
    "    data_collator=DataCollatorForTokenClassification(tokenizer=tokenizer),\n",
    "    compute_metrics=eval_matric\n",
    ")"
   ],
   "id": "9a3a6e46a3a0cba9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "trainer.train()",
   "id": "ab66c05795991259",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model.config.id2label = {idx: label for idx, label in enumerate(label_list)}\n",
    "model.config"
   ],
   "id": "4e01cf204e41c92d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"token-classification\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")"
   ],
   "id": "dd50fa0fd1c6acf5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(pipe(\"å°æ˜Žåœ¨åŒ—äº¬\"))\n",
    "print(pipe(\"å°æ˜Žåœ¨åŒ—äº¬å·¥ä½œ\"))\n",
    "print(pipe(\"å°æ˜Žåœ¨åŒ—äº¬ä¸Šç­\"))\n",
    "print(pipe(\"é‚“å°å¹³åœ¨åŒ—äº¬\"))\n",
    "print(pipe(\"é‚“å°å¹³åœ¨åŒ—äº¬ä¸Šç­\"))\n",
    "print(pipe(\"å°æ¸Šæƒ ä¸‰è®¿é—®ä¸­å›½\"))"
   ],
   "id": "c0e4fc9660baa248",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "# å¯¹æ¯”åˆ†æžï¼š\"å°æ˜Žåœ¨åŒ—äº¬ä¸Šç­\" vs \"é‚“å°å¹³åœ¨åŒ—äº¬ä¸Šç­\"\n",
    "test_pairs = [\n",
    "    (\"å°æ˜Žåœ¨åŒ—äº¬ä¸Šç­\", \"å°æ˜Ž\"),\n",
    "    (\"é‚“å°å¹³åœ¨åŒ—äº¬ä¸Šç­\", \"é‚“å°å¹³\"),\n",
    "]\n",
    "\n",
    "device = next(model.parameters()).device\n",
    "\n",
    "for text, name in test_pairs:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"æµ‹è¯•å¥å­: {text}\")\n",
    "    print(f\"ç›®æ ‡äººå: {name}\")\n",
    "    print('-'*80)\n",
    "\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "\n",
    "    tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
    "    predicted_labels = predictions[0].argmax(dim=-1)\n",
    "    scores = predictions[0].max(dim=-1).values\n",
    "\n",
    "    # æ˜¾ç¤ºæ¯ä¸ªtokençš„é¢„æµ‹\n",
    "    for i, (token, label_id, score) in enumerate(zip(tokens, predicted_labels, scores)):\n",
    "        if token in ['[CLS]', '[SEP]']:\n",
    "            continue\n",
    "\n",
    "        label = label_list[label_id.item()]\n",
    "\n",
    "        # é«˜äº®æ˜¾ç¤ºäººåtoken\n",
    "        if token in name:\n",
    "            marker = \"ðŸ‘‰\" if label in ['B-PER', 'I-PER'] else \"âŒ\"\n",
    "            print(f\"{marker} {token:8s} -> {label:8s} (ç½®ä¿¡åº¦: {score.item():.4f})\")\n",
    "        else:\n",
    "            print(f\"   {token:8s} -> {label:8s} (ç½®ä¿¡åº¦: {score.item():.4f})\")\n"
   ],
   "id": "c7a6184e317c961e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
