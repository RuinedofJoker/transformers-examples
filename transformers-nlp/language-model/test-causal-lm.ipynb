{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T06:31:08.499187Z",
     "start_time": "2026-02-13T06:31:08.495779Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "os.environ[\"TORCH_ROCM_AOTRITON_ENABLE_EXPERIMENTAL\"] = \"1\""
   ],
   "id": "844d857294548f10",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-02-13T06:31:17.148103Z",
     "start_time": "2026-02-13T06:31:08.501570Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "datasets = load_dataset(\"0xDing/wikipedia-cn-20230720-filtered\", split=\"train\")"
   ],
   "id": "6806d5c5bc3bbf7",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T06:31:24.331655Z",
     "start_time": "2026-02-13T06:31:17.209433Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Langboat/bloom-389m-zh\")"
   ],
   "id": "9c0fb2b99da4cda8",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T06:31:28.431723Z",
     "start_time": "2026-02-13T06:31:24.342304Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"Langboat/bloom-389m-zh\").to(\"cuda\")"
   ],
   "id": "45da7e1c66529f15",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading weights:   0%|          | 0/294 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "20cb768f23024c6daa00dc729ea3ff60"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tied weights mapping and config for this model specifies to tie transformer.word_embeddings.weight to lm_head.weight, but both are present in the checkpoints, so we will NOT tie them. You should update the config with `tie_word_embeddings=False` to silence this warning\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T06:31:28.445222Z",
     "start_time": "2026-02-13T06:31:28.442738Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_function(examples, tokenizer=tokenizer):\n",
    "    contents = [v + tokenizer.eos_token for v in examples[\"completion\"]]\n",
    "    return tokenizer(contents, max_length=384, truncation=True)"
   ],
   "id": "ff162faf63b9d891",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T06:31:28.493198Z",
     "start_time": "2026-02-13T06:31:28.447130Z"
    }
   },
   "cell_type": "code",
   "source": "tokenized_datasets = datasets.map(process_function, batched=True, remove_columns=datasets.column_names)",
   "id": "cedc382cff1b8000",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T06:31:28.557629Z",
     "start_time": "2026-02-13T06:31:28.495136Z"
    }
   },
   "cell_type": "code",
   "source": "tokenized_datasets = tokenized_datasets.train_test_split(test_size=0.2)",
   "id": "be3dcec92bd0a6e3",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T06:31:28.590849Z",
     "start_time": "2026-02-13T06:31:28.560137Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "train_args = TrainingArguments(\n",
    "    output_dir=\"./causal_lm\",\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=4,\n",
    "    logging_steps=10,\n",
    "    num_train_epochs=1,\n",
    "    fp16=True,\n",
    "    report_to=[\"tensorboard\"],\n",
    "    learning_rate=2e-5,\n",
    "    warmup_steps=100\n",
    ")\n",
    "train_args"
   ],
   "id": "b388575650f0b24d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainingArguments(\n",
       "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
       "adam_beta1=0.9,\n",
       "adam_beta2=0.999,\n",
       "adam_epsilon=1e-08,\n",
       "auto_find_batch_size=False,\n",
       "average_tokens_across_devices=True,\n",
       "batch_eval_metrics=False,\n",
       "bf16=False,\n",
       "bf16_full_eval=False,\n",
       "data_seed=None,\n",
       "dataloader_drop_last=False,\n",
       "dataloader_num_workers=0,\n",
       "dataloader_persistent_workers=False,\n",
       "dataloader_pin_memory=True,\n",
       "dataloader_prefetch_factor=None,\n",
       "ddp_backend=None,\n",
       "ddp_broadcast_buffers=None,\n",
       "ddp_bucket_cap_mb=None,\n",
       "ddp_find_unused_parameters=None,\n",
       "ddp_timeout=1800,\n",
       "debug=[],\n",
       "deepspeed=None,\n",
       "disable_tqdm=False,\n",
       "do_eval=False,\n",
       "do_predict=False,\n",
       "do_train=False,\n",
       "enable_jit_checkpoint=False,\n",
       "eval_accumulation_steps=None,\n",
       "eval_delay=0,\n",
       "eval_do_concat_batches=True,\n",
       "eval_on_start=False,\n",
       "eval_steps=None,\n",
       "eval_strategy=IntervalStrategy.NO,\n",
       "eval_use_gather_object=False,\n",
       "fp16=True,\n",
       "fp16_full_eval=False,\n",
       "fsdp=[],\n",
       "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
       "full_determinism=False,\n",
       "gradient_accumulation_steps=4,\n",
       "gradient_checkpointing=False,\n",
       "gradient_checkpointing_kwargs=None,\n",
       "greater_is_better=None,\n",
       "group_by_length=False,\n",
       "hub_always_push=False,\n",
       "hub_model_id=None,\n",
       "hub_private_repo=None,\n",
       "hub_revision=None,\n",
       "hub_strategy=HubStrategy.EVERY_SAVE,\n",
       "hub_token=<HUB_TOKEN>,\n",
       "ignore_data_skip=False,\n",
       "include_for_metrics=[],\n",
       "include_num_input_tokens_seen=no,\n",
       "label_names=None,\n",
       "label_smoothing_factor=0.0,\n",
       "learning_rate=2e-05,\n",
       "length_column_name=length,\n",
       "liger_kernel_config=None,\n",
       "load_best_model_at_end=False,\n",
       "local_rank=-1,\n",
       "log_level=passive,\n",
       "log_level_replica=warning,\n",
       "log_on_each_node=True,\n",
       "logging_dir=None,\n",
       "logging_first_step=False,\n",
       "logging_nan_inf_filter=True,\n",
       "logging_steps=10,\n",
       "logging_strategy=IntervalStrategy.STEPS,\n",
       "lr_scheduler_kwargs=None,\n",
       "lr_scheduler_type=SchedulerType.LINEAR,\n",
       "max_grad_norm=1.0,\n",
       "max_steps=-1,\n",
       "metric_for_best_model=None,\n",
       "neftune_noise_alpha=None,\n",
       "num_train_epochs=1,\n",
       "optim=OptimizerNames.ADAMW_TORCH_FUSED,\n",
       "optim_args=None,\n",
       "optim_target_modules=None,\n",
       "output_dir=./causal_lm,\n",
       "parallelism_config=None,\n",
       "per_device_eval_batch_size=8,\n",
       "per_device_train_batch_size=8,\n",
       "prediction_loss_only=False,\n",
       "project=huggingface,\n",
       "push_to_hub=False,\n",
       "remove_unused_columns=True,\n",
       "report_to=['tensorboard'],\n",
       "restore_callback_states_from_checkpoint=False,\n",
       "resume_from_checkpoint=None,\n",
       "run_name=None,\n",
       "save_on_each_node=False,\n",
       "save_only_model=False,\n",
       "save_steps=500,\n",
       "save_strategy=SaveStrategy.STEPS,\n",
       "save_total_limit=None,\n",
       "seed=42,\n",
       "skip_memory_metrics=True,\n",
       "tf32=None,\n",
       "torch_compile=False,\n",
       "torch_compile_backend=None,\n",
       "torch_compile_mode=None,\n",
       "torch_empty_cache_steps=None,\n",
       "trackio_space_id=trackio,\n",
       "use_cache=False,\n",
       "use_cpu=False,\n",
       "use_liger_kernel=False,\n",
       "warmup_ratio=None,\n",
       "warmup_steps=100,\n",
       "weight_decay=0.0,\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T06:31:28.729988Z",
     "start_time": "2026-02-13T06:31:28.596615Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import Trainer, DataCollatorForLanguageModeling\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=train_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"].select(range(int(len(tokenized_datasets[\"train\"]) / 5))),\n",
    "    data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    ")"
   ],
   "id": "8f7b22328a131889",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T06:31:28.734487Z",
     "start_time": "2026-02-13T06:31:28.732511Z"
    }
   },
   "cell_type": "code",
   "source": "# trainer.train()",
   "id": "ad0677a432ed5756",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T06:31:28.805761Z",
     "start_time": "2026-02-13T06:31:28.736531Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)"
   ],
   "id": "b0e06d30b83a8912",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T06:31:34.022763Z",
     "start_time": "2026-02-13T06:31:28.808482Z"
    }
   },
   "cell_type": "code",
   "source": "pipe(\"西安交通大学博物馆（Xi'an Jiaotong University Museum）是一座位于西安\", max_length=128, do_sample=True)",
   "id": "52006ba71506e7a6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing `generation_config` together with generation-related arguments=({'do_sample', 'max_length'}) is deprecated and will be removed in future versions. Please pass either a `generation_config` object OR all generation parameters explicitly, but not both.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"西安交通大学博物馆（Xi'an Jiaotong University Museum）是一座位于西安市大唐芙蓉园内，陈列着唐宋时期的名家书画、唐代书法、唐代墓志铭和唐诗文等各种艺术珍品。西安交通大学博物馆为唐诗文类主题博物馆，展品包括唐诗、唐书、唐诗文、唐帖、唐碑、唐画、唐乐府、唐诗文集、唐诗文集整理研究等，其中《唐诗文选》、《唐诗集解》两本被文化部、中国文联授予“国家级非物质文化遗产”称号。西安交通大学博物馆有唐诗文展览厅、唐诗书论展览厅、唐诗文集展览厅、唐诗文整理研究展览厅、唐诗文书法展览厅、唐诗文绘画展览厅、唐诗文摄影展览厅、唐诗文文献资料陈列厅等。西安交通大学博物馆分三个展厅，分别是唐诗馆、唐书馆、唐诗文馆。唐诗馆为唐诗研究、鉴赏、鉴赏、鉴赏、鉴赏等各个领域的专题展览，包括唐诗作品展、唐诗鉴赏展、唐诗鉴赏研究展、唐诗文鉴赏展等。西安书论馆是书\"}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T06:32:43.147593Z",
     "start_time": "2026-02-13T06:32:39.450334Z"
    }
   },
   "cell_type": "code",
   "source": "pipe(\"第一把手枪局输了的情况下第二把应该\", max_length=128, do_sample=True)",
   "id": "1e3bc649d7e92a82",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=256) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': '第一把手枪局输了的情况下第二把应该让林小凤来打吧，林小凤在前面打起来，不过打起来没多大效果，林小凤就停了下来，然后把枪递给了他，他一看，就明白了，林小凤以前打过人，知道这把枪要杀人的，就拿过来，然后又递给了他，他说，林小凤，你快过来。林小凤马上就过来，就准备拿枪来打他，不过没想到林小凤的枪已经打进了他的体内，而且还是被林小凤的枪给打中，这个林小凤就只能死了。虽然林小凤的身体被击中了，但是林小凤还活着，他的腿也没事，但是他还是被林小凤的枪给打中了，林小凤就只能死了，不过林小凤的腿没事，所以他还是活了下来。不过林小凤还是被打了，他的腿又被打伤了，但是他还是坚持活着，不过这时候，他发现了一个小男孩，他叫小明，他就是林小凤的哥哥，小明就把他叫到自己的床下。小明看到林小凤，就上去把他抱了起来，然后小明就对林小凤'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
