{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6be9c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"HF_HOME\"] = \"/root/autodl-tmp/HF_download\"\n",
    "os.environ[\"MODELSCOPE_CACHE\"] = \"/root/autodl-tmp/MODELSCOPE_download\"\n",
    "os.environ[\"HF_TOKEN\"] = \"xxx\"\n",
    "# os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47217b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"http_proxy\"] = \"http://127.0.0.1:7890\"\n",
    "os.environ[\"https_proxy\"] = \"http://127.0.0.1:7890\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f61b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "print(\"transformers:\", transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1a39f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/root/autodl-tmp/MODELSCOPE_download/models/ZhipuAI/chatglm3-6b-base\", trust_remote_code=True)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bf1a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "  \"/root/autodl-tmp/MODELSCOPE_download/models/ZhipuAI/chatglm3-6b-base\",\n",
    "  torch_dtype=torch.bfloat16,\n",
    "  trust_remote_code=True,\n",
    "  low_cpu_mem_usage=True,\n",
    "  device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b9f254",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "datasets = Dataset.load_from_disk(\"/root/autodl-tmp/code/test-transformers/data/alpaca_data_zh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2bd4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_function(example):\n",
    "  MAX_LENGTH = 256\n",
    "  instruction = \"\\n\".join([example[\"instruction\"].strip(), example[\"input\"].strip()]).strip()\n",
    "  instruction = tokenizer.build_chat_input(instruction, history=[], role=\"user\")\n",
    "  response = tokenizer(\"\\n\" + example[\"output\"], add_special_tokens=False)\n",
    "  input_ids = instruction[\"input_ids\"][0].numpy().tolist() + response[\"input_ids\"] + [tokenizer.eos_token_id]\n",
    "  attention_mask =instruction[\"attention_mask\"][0].numpy().tolist() + response[\"attention_mask\"] + [1]\n",
    "  labels = [-100] * len(instruction[\"input_ids\"][0]) + response[\"input_ids\"] + [tokenizer.eos_token_id]\n",
    "  if len(input_ids) > MAX_LENGTH:\n",
    "    return {}\n",
    "  return {\n",
    "    \"input_ids\": input_ids,\n",
    "    \"attention_mask\": attention_mask,\n",
    "    \"labels\": labels\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2b6929",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = datasets.map(process_function, remove_columns=datasets.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6403b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "config = LoraConfig(task_type=TaskType.CAUSAL_LM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71e0f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_peft_model(model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afc0eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdb348b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7196d5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"/root/autodl-tmp/code/test-transformers/test-kbit/16bits-training/glm3-chatbot2\",\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    logging_steps=10,\n",
    "    num_train_epochs=1,\n",
    "    learning_rate=1e-4,\n",
    "    # remove_unused_columns=False,\n",
    "    save_strategy=\"epoch\",\n",
    "    report_to=[\"tensorboard\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cebf92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, DataCollatorForSeq2Seq\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_datasets.select(range(6000)),\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer, padding=True),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666827c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c13c726",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "  print(model.chat(tokenizer, \"考试的技巧有哪些？\", history=[]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
