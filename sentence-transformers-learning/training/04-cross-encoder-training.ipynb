{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-Encoder 训练实战\n",
    "\n",
    "官方文档：https://sbert.net/docs/cross_encoder/training_overview.html\n",
    "\n",
    "Cross-Encoder 与 Sentence Transformer（Bi-Encoder）的核心区别：\n",
    "- **Bi-Encoder**：两个句子分别编码，输出向量，用余弦相似度比较。速度快，适合大规模检索。\n",
    "- **Cross-Encoder**：两个句子拼接后一起输入模型，输出相关性分数。精度高，适合重排序。\n",
    "\n",
    "## 训练组件\n",
    "\n",
    "与 Sentence Transformer 训练类似，也是 6 要素：\n",
    "1. **CrossEncoder** — 模型\n",
    "2. **Dataset** — 训练数据\n",
    "3. **Loss** — 损失函数（注意：从 `cross_encoder.losses` 导入）\n",
    "4. **CrossEncoderTrainingArguments** — 训练参数\n",
    "5. **Evaluator** — 评估器（可选）\n",
    "6. **CrossEncoderTrainer** — 训练器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 损失函数选择\n",
    "\n",
    "| 场景 | Loss | 数据格式 |\n",
    "|------|------|----------|\n",
    "| **二分类（相关/不相关）** | BinaryCrossEntropyLoss | (query, doc, 0/1) |\n",
    "| **多分类** | CrossEntropyLoss | (sent1, sent2, class_id) |\n",
    "| **排序（无标签）** | MultipleNegativesRankingLoss | (query, positive) 或三元组 |\n",
    "| **排序（有标签）** | LambdaLoss / ListNetLoss | (query, [doc1, doc2...], [score1, score2...]) |\n",
    "| **蒸馏** | MSELoss / MarginMSELoss | (sent1, sent2, teacher_score) |\n",
    "\n",
    "最常用：**BinaryCrossEntropyLoss**（训练 reranker）和 **CrossEntropyLoss**（NLI 分类）"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## 实战1：NLI 分类（CrossEntropyLoss）\n\n使用 AllNLI 数据集训练 Cross-Encoder 做三分类（蕴含/矛盾/中立）。",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "from sentence_transformers import CrossEncoder\nfrom sentence_transformers.cross_encoder.trainer import CrossEncoderTrainer\nfrom sentence_transformers.cross_encoder.training_args import CrossEncoderTrainingArguments\nfrom sentence_transformers.cross_encoder.losses import CrossEntropyLoss\nfrom sentence_transformers.cross_encoder.evaluation import CrossEncoderClassificationEvaluator\nfrom datasets import load_dataset",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# 1. 加载模型（num_labels=3：蕴含/中立/矛盾）\nmodel = CrossEncoder(\"distilroberta-base\", num_labels=3)\nprint(model)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# 2. 加载 AllNLI 数据集（pair-class 格式：sentence1, sentence2, label）\n# label: 0=蕴含, 1=中立, 2=矛盾\ntrain_dataset = load_dataset(\"sentence-transformers/all-nli\", \"pair-class\", split=\"train\").select(range(10000))\neval_dataset = load_dataset(\"sentence-transformers/all-nli\", \"pair-class\", split=\"dev\").select(range(1000))\n\nprint(f\"训练集: {len(train_dataset)} 条\")\nprint(\"样本:\", train_dataset[0])",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# 3. 损失函数: CrossEntropyLoss（多分类）\ntrain_loss = CrossEntropyLoss(model)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# 4. 评估器: 分类准确率\ndev_evaluator = CrossEncoderClassificationEvaluator(\n    sentence_pairs=list(zip(eval_dataset[\"premise\"], eval_dataset[\"hypothesis\"])),\n    labels=eval_dataset[\"label\"],\n    name=\"nli-dev\",\n)\nprint(\"训练前评估:\")\ndev_evaluator(model)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# 5. 训练参数\nargs = CrossEncoderTrainingArguments(\n    output_dir=\"output/nli-cross-encoder\",\n    num_train_epochs=1,\n    per_device_train_batch_size=64,\n    per_device_eval_batch_size=64,\n    warmup_ratio=0.1,\n    fp16=True,\n    eval_strategy=\"steps\",\n    eval_steps=50,\n    save_strategy=\"steps\",\n    save_steps=50,\n    save_total_limit=2,\n    logging_steps=50,\n)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# 6. 训练\ntrainer = CrossEncoderTrainer(\n    model=model,\n    args=args,\n    train_dataset=train_dataset,\n    eval_dataset=eval_dataset,\n    loss=train_loss,\n    evaluator=dev_evaluator,\n)\ntrainer.train()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# 7. 测试推理\npairs = [\n    (\"A man is eating pizza\", \"A man eats something\"),      # 蕴含\n    (\"A black race car starts up\", \"A man is driving\"),     # 中立\n    (\"A woman is sleeping\", \"A man is running\"),            # 矛盾\n]\npredictions = model.predict(pairs)\nlabel_map = {0: \"蕴含\", 1: \"中立\", 2: \"矛盾\"}\nfor pair, pred in zip(pairs, predictions):\n    label = label_map[pred.argmax()]\n    print(f\"  {pair[0]} | {pair[1]} → {label} {pred}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 实战2：Reranker 训练（BinaryCrossEntropyLoss）\n\n使用 MS MARCO 数据集训练搜索重排序模型。数据格式：(query, passage, 0/1)。\n\n这是 Cross-Encoder 最核心的应用场景。",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "from sentence_transformers.cross_encoder.losses import BinaryCrossEntropyLoss\nfrom sentence_transformers.cross_encoder.evaluation import CrossEncoderRerankingEvaluator\n\n# 1. 加载 reranker 模型（num_labels=1：输出单个相关性分数）\nreranker = CrossEncoder(\"distilroberta-base\", num_labels=1)\nprint(reranker)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# 2. 加载 GooAQ 数据集（question-answer 对，适合 reranker 训练）\ntrain_dataset = load_dataset(\"sentence-transformers/gooaq\", split=\"train\").select(range(10000))\neval_dataset = load_dataset(\"sentence-transformers/gooaq\", split=\"train\").select(range(10000, 11000))\n\nprint(f\"训练集: {len(train_dataset)} 条\")\nprint(\"样本:\", train_dataset[0])",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# 3. 损失函数: BinaryCrossEntropyLoss\n# GooAQ 是正样本对格式，BCE 会利用 in-batch negatives\nreranker_loss = BinaryCrossEntropyLoss(reranker)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# 4. 评估器: 重排序评估（MRR@10）\n# 构造评估数据：每个 query 对应 1 个正样本 + batch 内其他 answer 作为负样本\nsamples = [\n    {\n        \"query\": eval_dataset[i][\"question\"],\n        \"positive\": [eval_dataset[i][\"answer\"]],\n        \"negative\": [eval_dataset[j][\"answer\"] for j in range(len(eval_dataset)) if j != i][:9],\n    }\n    for i in range(100)  # 取 100 条做评估\n]\ndev_evaluator = CrossEncoderRerankingEvaluator(samples=samples, name=\"gooaq-dev\")\nprint(\"训练前评估:\")\ndev_evaluator(reranker)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# 5. 训练参数\nreranker_args = CrossEncoderTrainingArguments(\n    output_dir=\"output/gooaq-reranker\",\n    num_train_epochs=1,\n    per_device_train_batch_size=64,\n    per_device_eval_batch_size=64,\n    warmup_ratio=0.1,\n    fp16=True,\n    eval_strategy=\"steps\",\n    eval_steps=50,\n    save_strategy=\"steps\",\n    save_steps=50,\n    save_total_limit=2,\n    logging_steps=50,\n)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# 6. 训练\nreranker_trainer = CrossEncoderTrainer(\n    model=reranker,\n    args=reranker_args,\n    train_dataset=train_dataset,\n    eval_dataset=eval_dataset,\n    loss=reranker_loss,\n    evaluator=dev_evaluator,\n)\nreranker_trainer.train()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# 7. 测试 reranker 排序效果\nquery = \"How many people live in Berlin?\"\ndocuments = [\n    \"Berlin has a population of 3,520,031 registered inhabitants.\",\n    \"Berlin is well known for its museums.\",\n    \"Germany is a country in Europe.\",\n    \"New York City is the most populous city in the United States.\",\n]\nrankings = reranker.rank(query, documents)\nprint(f\"Query: {query}\\n\")\nfor r in rankings:\n    print(f\"  [{r['score']:.4f}] {documents[r['corpus_id']]}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# 8. 保存模型\nreranker.save(\"output/gooaq-reranker/final\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Cross-Encoder vs Bi-Encoder 训练对比\n\n| 对比项 | Bi-Encoder (SentenceTransformer) | Cross-Encoder |\n|--------|----------------------------------|---------------|\n| **导入路径** | `sentence_transformers.losses` | `sentence_transformers.cross_encoder.losses` |\n| **Trainer** | `SentenceTransformerTrainer` | `CrossEncoderTrainer` |\n| **TrainingArgs** | `SentenceTransformerTrainingArguments` | `CrossEncoderTrainingArguments` |\n| **num_labels** | 不需要 | 分类=类别数，回归/排序=1 |\n| **推理方式** | `model.encode()` → 向量 | `model.predict()` → 分数 |\n| **典型应用** | 大规模检索、聚类 | 精排、NLI 分类 |\n| **速度** | 快（独立编码） | 慢（拼接编码） |\n| **精度** | 相对低 | 相对高 |",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}