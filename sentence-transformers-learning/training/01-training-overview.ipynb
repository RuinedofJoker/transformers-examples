{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence Transformers 训练概述\n",
    "\n",
    "官方文档：https://sbert.net/docs/sentence_transformer/training_overview.html\n",
    "\n",
    "## 训练六要素\n",
    "\n",
    "1. **Model** — 基础模型\n",
    "2. **Dataset** — 训练数据\n",
    "3. **Loss** — 损失函数\n",
    "4. **TrainingArguments** — 训练参数\n",
    "5. **Evaluator** — 评估器（可选）\n",
    "6. **Trainer** — 训练器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据格式\n",
    "\n",
    "训练数据格式决定了可以使用哪些损失函数：\n",
    "\n",
    "| 数据格式 | 示例 | 适用 Loss |\n",
    "|---------|------|----------|\n",
    "| **正样本对** (anchor, positive) | (query, relevant_doc) | MultipleNegativesRankingLoss |\n",
    "| **三元组** (anchor, positive, negative) | (query, good_doc, bad_doc) | TripletLoss, MNRL |\n",
    "| **带分数的句子对** (sent1, sent2, score) | (\"天气好\", \"阳光明媚\", 0.9) | CosineSimilarityLoss, CoSENTLoss |\n",
    "| **带类别的文本** (text, label) | (\"好评\", 1) | BatchAllTripletLoss |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 损失函数选择指南\n",
    "\n",
    "最常用的两种场景：\n",
    "\n",
    "### 1. 有正样本对/三元组 → MultipleNegativesRankingLoss (MNRL)\n",
    "- 训练效果最好的 embedding 模型大多使用此 loss\n",
    "- 利用 in-batch negatives，batch 越大效果越好\n",
    "- CachedMultipleNegativesRankingLoss 可在显存有限时模拟大 batch\n",
    "\n",
    "### 2. 有相似度分数 → CoSENTLoss\n",
    "- 比传统的 CosineSimilarityLoss 效果更好\n",
    "- 适合 STS（语义文本相似度）任务\n",
    "\n",
    "### Loss 修饰器（可叠加）\n",
    "- **MatryoshkaLoss** — 支持截断向量维度（如 768→256→128）\n",
    "- **AdaptiveLayerLoss** — 支持使用更少的 Transformer 层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, load_dataset\n",
    "\n",
    "# 格式1：带分数的句子对（STS）\n",
    "sts_dataset = load_dataset(\"sentence-transformers/stsb\", split=\"train[:5]\")\n",
    "print(\"=== STS 数据格式 ===\")\n",
    "print(sts_dataset)\n",
    "print(sts_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 格式2：三元组（NLI）\n",
    "nli_dataset = load_dataset(\"sentence-transformers/all-nli\", \"triplet\", split=\"train[:5]\")\n",
    "print(\"=== NLI 三元组格式 ===\")\n",
    "print(nli_dataset)\n",
    "print(nli_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 格式3：自定义数据集\n",
    "custom_dataset = Dataset.from_dict({\n",
    "    \"sentence1\": [\"深度学习很有趣\", \"Python是好语言\"],\n",
    "    \"sentence2\": [\"神经网络很有意思\", \"Java也不错\"],\n",
    "    \"label\": [0.9, 0.5],\n",
    "})\n",
    "print(\"=== 自定义数据格式 ===\")\n",
    "print(custom_dataset[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": { "display_name": "model_env", "language": "python", "name": "python3" },
  "language_info": { "name": "python", "version": "3.12.0" }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}